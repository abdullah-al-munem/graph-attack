{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(1) in 'proposed_model_cora_gcn_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>budget_number</th>\n",
       "      <th>miss-classification_modified</th>\n",
       "      <th>node_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.45</td>\n",
       "      <td>[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  budget_number  miss-classification_modified  \\\n",
       "0           0              1                          0.40   \n",
       "1           1              2                          0.45   \n",
       "2           2              3                          0.55   \n",
       "3           3              4                          0.60   \n",
       "4           4              5                          0.65   \n",
       "\n",
       "                                           node_list  \n",
       "0  [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...  \n",
       "1  [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...  \n",
       "2  [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...  \n",
       "3  [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...  \n",
       "4  [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('proposed_model_cora_gcn_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[929, 1163, 1347, 2077, 2082, 1049, 1185, 2260, 1669, 1486, 1104, 2429, 1207, 1068, 1891, 2379, 720, 2323, 2200, 1167, 1924, 1180, 413, 832, 2148, 159, 1878, 2481, 1448, 1745, 1505, 1547, 1938, 805, 354, 1321, 97, 811, 72, 366]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'node_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = ast.literal_eval(df.loc[0,'node_list'])\n",
    "type(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260, 1669, 1486, 1104, 2429, 1207, 1068, 1891, 2379, 720, 2323, 2200, 1167, 1924, 1180, 413, 832, 2148, 159, 1878, 2481, 1448, 1745, 1505, 1547, 1938, 805, 354, 1321, 97, 811, 72, 366]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m li_2 \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m li_2\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ast.py:96\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ast.py:95\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ast.py:66\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalformed node or string: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(node))\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: [929, 1163, 1347, 2077, 2082, 1049, 1185, 2260, 1669, 1486, 1104, 2429, 1207, 1068, 1891, 2379, 720, 2323, 2200, 1167, 1924, 1180, 413, 832, 2148, 159, 1878, 2481, 1448, 1745, 1505, 1547, 1938, 805, 354, 1321, 97, 811, 72, 366]"
     ]
    }
   ],
   "source": [
    "li_2 = ast.literal_eval(li)\n",
    "li_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = ['proposed_model_polblogs_gcn_1.csv']\n",
    "csv_file_list = [file for file in li if ('.csv' in  file) and (str(2) in file)]\n",
    "csv_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\py_res\\venv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.data import Dataset, Dpr2Pyg, Pyg2Dpr\n",
    "from deeprobust.graph.defense import GCN\n",
    "data = Dataset(root=r'F:\\py_res', name='cora') # load clean graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "f:\\py_res\\venv2\\lib\\site-packages\\deeprobust\\graph\\data\\pyg_dataset.py:48: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  edge_index = torch.LongTensor(dpr_data.adj.nonzero())\n",
      "Done!\n",
      "f:\\py_res\\venv2\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2485, 1433], edge_index=[2, 10138], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = Dpr2Pyg(data)[0]\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.x[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 1433)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [929, 1554, 1504, 1163, 1342, 2406, 2307, 1185, 1347, 2260, 2341, 448, 1800, 1725, 2057, 136, 1995, 530, 1559, 941, 838, 1079, 1860, 477, 6, 836, 479, 2345, 1074, 1143, 2060, 545, 336, 1230, 1546, 231, 1254, 1397, 496, 1476]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset_from_deeprobust, destructuring_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\py_res\\venv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.data import Dataset, Dpr2Pyg\n",
    "\n",
    "target_node = 7\n",
    " \n",
    "data = Dataset(root=r'./', name='cora')\n",
    "data2 = data\n",
    "adj2, features2, labels2 = data2.adj, data2.features, data2.labels\n",
    "idx_train2, idx_val2, idx_test2 = data2.idx_train, data2.idx_val, data2.idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\py_res\\venv2\\lib\\site-packages\\deeprobust\\graph\\utils.py:356: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  return torch.sparse.FloatTensor(sparseconcat.t(),sparsedata,torch.Size(sparse_mx.shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device='cuda'\n",
    "gcn = GCN(nfeat=features2.shape[1], nhid=16, nclass=labels2.max().item() + 1, dropout=0.5, device=device)\n",
    "gcn = gcn.to(device)\n",
    "gcn.fit(features2, adj2, labels2, idx_train2, idx_val2, patience=30, train_iters=100)\n",
    "gcn.eval()\n",
    "output = gcn.predict()\n",
    "label = output.argmax(1)[target_node]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gcn.eval()\n",
    "output_modified = gcn.predict(features=features2, adj=adj2)\n",
    "label = output.argmax(1)[target_node]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linearized_weight():\n",
    "    surrogate = gcn\n",
    "    W = surrogate.gc1.weight @ surrogate.gc2.weight\n",
    "    return W.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = get_linearized_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pyg_data = Dpr2Pyg(Dataset(root=r'./', name='cora'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\py_res\\venv2\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2485, 1433], edge_index=[2, 10138], y=[2485], train_mask=[2485], val_mask=[2485], test_mask=[2485])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10138])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_data[0].edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyg_data[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m gcn\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m modified_adj \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(pyg_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m----> 6\u001b[0m output_modified \u001b[38;5;241m=\u001b[39m \u001b[43mgcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodified_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)[target_node]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(label)\n",
      "File \u001b[1;32mf:\\py_res\\venv2\\lib\\site-packages\\deeprobust\\graph\\defense\\gcn.py:339\u001b[0m, in \u001b[0;36mGCN.predict\u001b[1;34m(self, features, adj)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_sparse_tensor(adj):\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_norm \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_adj_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_norm \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnormalize_adj_tensor(adj)\n",
      "File \u001b[1;32mf:\\py_res\\venv2\\lib\\site-packages\\deeprobust\\graph\\utils.py:215\u001b[0m, in \u001b[0;36mnormalize_adj_tensor\u001b[1;34m(adj, sparse)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# warnings.warn('If you find the training process is too slow, you can uncomment line 207 in deeprobust/graph/utils.py. Note that you need to install torch_sparse')\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# TODO if this is too slow, uncomment the following code,\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# but you need to install torch_scatter\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# return normalize_sparse_tensor(adj)\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     adj \u001b[38;5;241m=\u001b[39m to_scipy(adj)\n\u001b[1;32m--> 215\u001b[0m     mx \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_adj\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse_mx_to_torch_sparse_tensor(mx)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\py_res\\venv2\\lib\\site-packages\\deeprobust\\graph\\utils.py:160\u001b[0m, in \u001b[0;36mnormalize_adj\u001b[1;34m(mx)\u001b[0m\n\u001b[0;32m    158\u001b[0m     mx \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39mtolil()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mx[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m--> 160\u001b[0m     mx \u001b[38;5;241m=\u001b[39m \u001b[43mmx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m rowsum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mx\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    162\u001b[0m r_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(rowsum, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mf:\\py_res\\venv2\\lib\\site-packages\\scipy\\sparse\\_base.py:471\u001b[0m, in \u001b[0;36mspmatrix.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m isspmatrix(other):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m--> 471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_sparse(other)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n",
      "\u001b[1;31mValueError\u001b[0m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "gcn.eval()\n",
    "modified_adj = sp.csr_matrix(pyg_data[0].edge_index.T.numpy())\n",
    "\n",
    "output_modified = gcn.predict(features=features2, adj=modified_adj)\n",
    "label = output.argmax(1)[target_node]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
